---
title: "hw5_ilz2105"
author: "Lulu Zhang"
date: "11/2/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      warning = FALSE)
```

__Problem 1__ 

```{r, message=FALSE}
library(tidyverse)
library(rvest)
library(readr)
library(broom)

set.seed(10)
```

For numeric variables, you should fill in missing values with the mean of non-missing values
For character variables, you should fill in missing values with "virginica"

```{r}
iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species)) %>% 
  janitor::clean_names()

clean_data = function(x) {
  if (is.numeric(x)){
    replace(x, is.na(x), round(mean(x, na.rm = TRUE), digits = 1))
  }
  else if(!is.numeric(x)){replace(x, is.na(x), "virginica")}
}


final_iris = map_df(iris_with_missing, ~clean_data(.x))
final_iris
```

The `final_iris` df shows the iris dataset when the NA values for the numeric variables are filled in with the mean 
of the non-missing values and the character variables are filled in with "virginica`.

__Problem 2__

For this problem I made a dataframe with all the file names from the `data` folder in the `_MACOSX` folder, then I 
iterated over file names and read in data for each subject using purrr::map and saved the result as a new variable 
in the dataframe. Then I tidied the result; manipulated file names to include control arm and subject ID, make sure 
weekly observations are “tidy”, and do any other tidying that’s necessary.

```{r}
files = tibble(
  names = list.files(path = "./data/", all.files = TRUE, no.. = TRUE),
  paths = str_c("./data/", names))

func = function(x){
  read_csv(x)
}
study = files %>% 
  mutate(source = map(files$paths, func)) %>% 
  unnest(cols = c(source)) %>% 
  janitor::clean_names() %>% 
  select(-paths) %>% 
  separate(names, into = c("study_arm","subject_id", "type")) %>%
  select(-type) %>% 
   pivot_longer(
     cols = starts_with("week_"),
    names_to = "week",
    names_prefix = "week_",
    values_to = "value") %>% 
  group_by(subject_id) 

```
```{r}
# spaghetti plot

plot = study %>% 
  ggplot(aes(x = week, y = value, color = study_arm, group = study_arm))+
  geom_path()+
  labs( title = "Longitudinal Study: Observations on Each Subject Over Time",
        x = "Week",
        y = "Observations")+
  theme(plot.title = element_text(hjust = 0.5))
plot

```
The spaghetti plot shows the observations on each subject over time. The experiment arm has higher observation values compared to the control arm, on average. Week 6 shows the lowest observation values for the control arm with a value of almost -2.5, and week 7 has the peak observation value for the exp arm which was about 7.6. 


__Problem 3__

First set the following design elements:

Fix n=30
Fix xi1 as draws from a standard Normal distribution
Fix β0=2
Fix σ2=50
Set β1=0. Generate 10000 datasets from the model
yi=β0+β1xi1+ϵi

```{r}
generate_reg = function(n = 30, beta0 = 2, beta1, var = 50) {
  
  p3_data = tibble(
  x = rnorm(n, mean = 0, sd = 1),
  y = beta0 + beta1 * x + rnorm(n, 0, var^0.5)
)
  
  ls_fit = lm(y ~ x, data = p3_data)
  
  tidy(ls_fit)
}

results = 
  rerun(10000, generate_reg(n = 30, var = 50, beta1 = 0)) %>% 
  bind_rows() %>% 
  select(term, estimate, p.value) %>% 
  filter(term == "x")


power = tibble(
  beta_1 = c(0, 1, 2, 3, 4, 5, 6)) %>% 
  mutate(
    output = map(.x = beta_1, ~rerun(10000, generate_reg(beta1 = .x))),
    est = map(output, bind_rows)) %>% 
  select(-output) %>% 
  unnest(est) %>% 
  select(beta_1, term, estimate, p.value) %>% 
  filter(term == "x")

final = power %>% 
  group_by(beta_1) %>% 
  summarize(sum_p = sum(p.value < 0.05),
            total_power = sum_p/n()) %>% 
  ggplot(aes(x = beta_1, y = total_power, fill = total_power))+
  geom_bar(stat = "identity")+
  labs(title = "association between effect size & power",
       x = "true value of beta1",
       y = "power") +
  theme(plot.title = element_text(hjust = 0.5))

final
```

The plot above shows the positive association between power and the effect size. As the power increases (as the proportion of times the null was rejected increases), the true value of beta1 or the effect size increases. 

Next I made a second plot showing the average estimate of β^1 only in samples for which the null was rejected on the y axis and the true value of β1 on the x axis. 

```{r}
final_restricted = 
  power %>% 
  group_by(beta_1) %>% 
  summarize(
    b1_avg_est = mean(estimate),
    b1_signif = mean(estimate[p.value < 0.05], na.rm = TRUE)) %>% 
  ggplot(aes(x = beta_1, y = b1_avg_est ,fill = "maroon4"))+
  geom_bar(stat = "identity")+
  geom_point(aes(x = beta_1, y = b1_signif))+
  labs( title = "true vs. average B1 for samples",
        x = "true value of B1",
        y = "average estimate of B1")+
  theme( plot.title = element_text(hjust = 0.5),
    legend.position = "bottom") +
  scale_y_continuous(breaks = seq(-1, 8, 1)) +
  scale_fill_identity(name = 'Legend', guide = 'legend',
                      labels = c('True vs. Estimated Values of β1')) +
  theme(plot.title = element_text(hjust = 0.5))

final_restricted
```

The black dots represent the average beta1 estimates only in samples for which the null was rejected while the maroon bars represent
the average estimates of beta1. The sample average of beta1 across tests for which the null was rejected approximately is not equal to 
the true value of beta1 in all of the tests. When beta1 = 0-4, the sample averages are not equal to the true value, but for beta1 = 5-6,
the sample average gets closer to the true value. This is because larger efffect sizes are easier to estimate compared to smaller effect 
sizes because they are eaiser to detect-this is why as the beta1 gets larger, the sample averages get more accurate. 
